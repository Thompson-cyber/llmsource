# This code was generated by ChatGPT 3.5. Prompt:
# write me a web scraper in python that sends the text content of the webpage to the chatgpt API, then outputs the email addresses on that webpage to a local text file

import os
import re
import requests
from bs4 import BeautifulSoup
import openai
from dotenv import load_dotenv

load_dotenv()

def extract_emails(text):
    return re.findall(r'[\w\.-]+@[\w\.-]+', text)

# Function to send text to ChatGPT API
def chat_with_gpt(text):
    response = openai.ChatCompletion.create(
        model="text-davinci-003",
        messages=[
            {"role": "system", "content": "You are a web scraper."},
            {"role": "user", "content": text}
        ]
    )
    return response.choices[0].message['content']

def scrape_and_extract_emails(url: str) -> list[str]:
    response = requests.get(url)
    
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        # Extract text content from the webpage
        text_content = soup.get_text()
        # Send text content to ChatGPT API
        gpt_response = chat_with_gpt(text_content)
        # Extract email addresses from GPT-3 response
        emails = extract_emails(gpt_response)
        return emails
    else:
        print("Failed to fetch webpage:", response.status_code)
        return []

# Function to write email addresses to a local text file
def write_emails_to_file(emails, filename='emails.txt'):
    with open(filename, 'w') as file:
        for email in emails:
            file.write(email + '\n')

def main():
    emails = scrape_and_extract_emails(os.getenv('SCRAPE_URL'))

    # Write email addresses to a local text file
    if emails:
        write_emails_to_file(emails)
        print("Email addresses saved to 'emails.txt'")
    else:
        print("No email addresses found on the webpage.")

if __name__ == "__main__":
    main()
